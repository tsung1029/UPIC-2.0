3D OpenMP Particle-in-Cell (PIC) BEPS3 codes
by Viktor K. Decyk, UCLA
copyright 1994-2017, regents of the university of california

These codes are part of the UPIC 2.0.3 Framework.  The primary purpose
of this framework is to provide trusted components for building and
customizing parallel Particle-in-Cell codes for plasma simulation.
The framework provides libraries as well as 3 different reference
applications illustrating their use.  The libraries are designed to
work with up to 3 levels of parallelization (using MPI for distributed
memory, OpenMP for shared memory, local vectorization).  Currently only
the first two are supported.  The reference applications are designed to
provide basic functionality common to many PIC codes, and are intended
to be customized and specialized by users for specific applications.
Currently, only spectral field solvers are currently supported, but the
particle methods are designed to be general.  In addition, other test
codes will also be provided, illustrating the use of some specific
component.  This is primarily intended to users who wish to incorporate
some component into an already existing code. Currently, only two test
codes are provided.

A Software License for use of this code is in the document:
Documents/License(CommercialReservation)

A description of the design of these codes and its components is in the
document:
Documents/BEPS3Design.pdf

A description of the current capabilities of these codes and its
components is in the document:
Documents/BEPS3Overview.pdf
Documents/MPI-OpenMP-PIC.pdf

Details about the mathematical equations and units used in this code is
given in the document:
Documents/UPICModels.pdf.

A description of the input parameters to these codes and their default
values are in the document:
mbeps3.source/input3mod.f90

For details about compilation and running, see mpbeps3.source/README

There are 3 Fortran reference codes for electrostatic, electromagnetic,
and darwin models, called mpbeps2, mpbbeps2, and mpdbeps2, respectively.
They are designed for Linux but will also compile for Mac OS X.  OpenMP
and MPI are used for parallelization, but if MPI is not available, the
codes can be compiled for OpenMP only

A number of Directories are being developed to provide test codes to
illustrate components of these codes.  These are primarily intended for
those who wish to incorporate only pieces of the code into their own
codes.  The first one of these is the directory Periodic which
shows how to solve for the potential, longitudinal electric field,
vector potential and magnetic field using periodic boundary conditions.
A third one is the directory ReadFiles which contains sample programs
that illustrate how to read periodic fields which have been written
using simple Fortran IO by the reference applications.

To compile all these codes in the current (mpbeps3) directory, execute:

make

To compile just one, execute:

make program_name

where program_name is either: mpbeps3, mpbbeps3, or mpdbeps23

To execute, one first needs to copy an input file.  There are some
examples in the Examples directory in the current directory.  Files for
the electrostatic code are in the Examples/ES directory, those for the
electromagnetic code are in the Examples/EM directory, and those for the
darwin code are in the Examples/Darwin directory. To copy the the plasma
wave example for electrostatic code, type:

cp Examples/ES/input3.plasma input3

The command to execute a program with both MPI and OpenMP varies from
one system to another.  One possible command is:

mpiexec -np nproc -perhost n ./program_name

where nproc is the number of processors to be used, and where n is the
number of MPI nodes per host.

By default, OpenMP will use the maximum number of processors it can find
on the MPI node.  If the user wants to control the number of threads, a
parameter nvpp can be set in the main program.  In addition, the
environment variable OMP_NUM_THREADS may need to be set to the maximum
number of threads per node expected.

To compile all these codes without MPI, execute:

make nompi

To compile just one, execute:

make program_name

where program_name is either: mbeps3, mbbeps3, or mdbeps3

To execute witout MPI, type the name of the executable:

./program_name

To delete compiled libraries (.o files) and the executables, execute:

make clobber

For more details about compilation, including use of double precision,
see mpbeps3.source/README.

If files are generated by the reference applications, sample programs
to read them are available in the Directory ReadFiles.  Fortran programs
(preadf3, pvreadf3, pflreadf3, pfvreadf3, ptreadf3, and psreadf3) can be
compiled by executing:

make readf

These programs can be used to read scalar, vector, fluid, velocity, or
test particle trajectory data.

There are also 6 Python scripts available (preadf3.py, pvreadf3.py,
pflreadf3.py, pfvreadf3.py, ptreadf3.py, and psreadf3.p).  They require
a dynamic library (libcmfield3.so).  To compile the library and copy the
scripts, execute:

make pyreadf

The execute the scripts, type:

python scriptname

where scriptname is either: preadf3.py, pvreadf3.py, pflreadf3.py, 
pfvreadf3.py, ptreadf3.py, or psreadf3.py

To delete the library and the files in the mbeps3 directory, execute:

make readfclobber

********************************************************************************************************


** A Quick note for compiling on the Mac:

As Mac's have multiple compilers (LLVM with Xcode and GCC via homebrew).  Sometimes compiling is not straight forward.  
In my opinion the UNIX 1/2 of OS X is not very standardized and it is not always easy to compile the code under OS X.  

To compile UPIC, you need 

*** A c-compiler
*** A Fortran compiler
*** Some version of MPI (I am using Open-MPI in this example but MPICH should work)
*** HDF5 for I/O (for OpenMP I/O)

I was not always a fan of Home Brew, but it is much faster than installing each software by source and I am more and more 
impressed by its results.  It also produces results which can be reproduced on all computers so it makes software distribution
more uniform and predictable.  

To prepare your system, please type the following commands:

brew install gcc (this actually installs the Fortran compiler)
brew install open-mpi
brew install hdf5-mpi

This will provide all the libraries needed for UPIC.

As of October 2020, at the end of updating homebrew, you should see the following results:


uclapic$ mpicc --version
Apple clang version 12.0.0 (clang-1200.0.32.2)
Target: x86_64-apple-darwin19.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
uclapic$ mpif90 --version
GNU Fortran (Homebrew GCC 10.2.0) 10.2.0
Copyright (C) 2020 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


